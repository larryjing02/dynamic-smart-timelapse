{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 Timelapse: Modified speed, added buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output video filename\n",
    "FILENAME  = 'outputMACtest.avi'\n",
    "\n",
    "# Camera variables:\n",
    "# If motion detection triggered too easily, turn auto-exposure to False and set exposure lock below\n",
    "AUTO_EXPOSURE = True\n",
    "\n",
    "# Note: set camera exposure slightly lower (so frame looks darker) if motion detection triggers too easily\n",
    "EXPOSURE_LOCK = -7\n",
    "\n",
    "CAMERA_SOURCE = 0\n",
    "\n",
    "# Minimum size of detected contour to trigger motion detection\n",
    "# Increase if motion/face detection too sensitive, decrease if motion not being detected\n",
    "MIN_CONTOUR_SIZE = 5000\n",
    "\n",
    "# How many frames to look behind for comparision during motion detection\n",
    "FRAME_COMPARISON_DISTANCE = 15\n",
    "\n",
    "# Specify whether or not to draw detection boxes\n",
    "DRAW_FACE_BOXES = True\n",
    "DRAW_MOTION_BOXES = True\n",
    "\n",
    "# Specify whether or not to display image as code is running\n",
    "DISPLAY_IMAGE = True\n",
    "\n",
    "# Speed at which different event type frames are grabbed\n",
    "FACE_EVENT_PERIOD = 1\n",
    "MOTION_EVENT_PERIOD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three states:\n",
    "# 1. Idle (no motion detected)\n",
    "# 2. Motion (movement is detected)\n",
    "# 3. Person (face is detected)\n",
    "state = 0\n",
    "comparison_frames = [None for i in range(FRAME_COMPARISON_DISTANCE)]\n",
    "ref = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaces(curFrame, frame):\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(curFrame, 1.1, 6)\n",
    "    detected = False\n",
    "    \n",
    "    # loop over the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # If the contour is too small, ignore it\n",
    "        if w*h < MIN_CONTOUR_SIZE:\n",
    "            continue\n",
    "            \n",
    "        if not detected:\n",
    "            cv2.putText(frame, \"Face Detected\", (20,20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            detected = True\n",
    "            if not DRAW_FACE_BOXES:\n",
    "                break\n",
    "            \n",
    "        # Compute bounding box & draw on frame, update text\n",
    "        if DRAW_FACE_BOXES:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "    return detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectMotion(refFrame, curFrame, frame):\n",
    "    # Compute absolute difference between current frame and first frame\n",
    "    frameDelta = cv2.absdiff(refFrame, curFrame)\n",
    "    thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Dilate thresholded image to fill in holes\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours on thresholded image\n",
    "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    detected = False\n",
    "    \n",
    "    # loop over the contours\n",
    "    for c in contours:\n",
    "        # If the contour is too small, ignore it\n",
    "        if cv2.contourArea(c) < MIN_CONTOUR_SIZE:\n",
    "            continue\n",
    "            \n",
    "        if not detected:\n",
    "            cv2.putText(frame, \"Motion Detected\", (20,20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            detected = True\n",
    "            if not DRAW_MOTION_BOXES:\n",
    "                break\n",
    "\n",
    "        # Compute bounding box & draw on frame, update text\n",
    "        if DRAW_MOTION_BOXES:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "    return detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video in 3... 2... 1... \n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Current non-event playback speed: 4x\n",
      "Current non-event playback speed: 8x\n",
      "Face Detected, non-event period just ended!\n",
      "Motion just ended, non-event period starting now!\n",
      "Face Detected, non-event period just ended!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the face detecter\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize video source - use webcam for testing\n",
    "vs = cv2.VideoCapture(CAMERA_SOURCE)\n",
    "# Set exposure\n",
    "if AUTO_EXPOSURE:\n",
    "    vs.set(cv2.CAP_PROP_AUTO_EXPOSURE, 3)\n",
    "else:\n",
    "    vs.set(cv2.CAP_PROP_EXPOSURE, EXPOSURE_LOCK)\n",
    "\n",
    "\n",
    "# Output will be written to output.avi\n",
    "out = cv2.VideoWriter(\n",
    "    FILENAME,\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    15.,\n",
    "    (640,480))\n",
    "\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# Allow time for source to begin recording (camera startup)\n",
    "print(\"Starting video in 3... \",end=\"\")\n",
    "time.sleep(1)\n",
    "print(\"2... \",end=\"\")\n",
    "time.sleep(1)\n",
    "print(\"1... \")\n",
    "time.sleep(1)\n",
    "\n",
    "# Initialize dynamic frame grabbing variables\n",
    "grab_period = MOTION_EVENT_PERIOD\n",
    "elapsed_frames = 0\n",
    "doubler = vs.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Initialize circular array\n",
    "for i in range(FRAME_COMPARISON_DISTANCE):\n",
    "    ret, frame = vs.read()\n",
    "    if ret:\n",
    "        # TODO: Look into changing cv2 to imutils resize\n",
    "        frame = imutils.resize(frame, width = 640)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        comparison_frames[i] = cv2.GaussianBlur(frame, (41,41), 0)\n",
    "        if i == FRAME_COMPARISON_DISTANCE - 1:\n",
    "            if detectFaces(frame, frame):\n",
    "                state = 3\n",
    "            elif detectMotion(comparison_frames[0], comparison_frames[i], frame):\n",
    "                state = 2\n",
    "            else:\n",
    "                state = 1\n",
    "    else:\n",
    "        print(\"Error with Video Capture Source\")\n",
    "        exit()\n",
    "\n",
    "# Start normal loop, continues until terminated (press 'q')\n",
    "current_frame = 0\n",
    "while True:\n",
    "    ret, frame = vs.read()\n",
    "    if ret:\n",
    "        # Ensure reference frame for motion detection is fine\n",
    "        # TODO: Refactor to detectMotion method?\n",
    "        if comparison_frames[ref] is None:\n",
    "            print(\"Error with Comparison Frames\")\n",
    "            exit()\n",
    "        \n",
    "        # Advance frame counter\n",
    "        current_frame += 1\n",
    "        frame = imutils.resize(frame, width = 640)\n",
    "        #frame = cv2.resize(frame, (640, 480))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if detectFaces(gray, frame):\n",
    "            # Nonevent period just ended\n",
    "            if state == 1:\n",
    "                print(\"Face Detected, non-event period just ended!\")\n",
    "            state = 3\n",
    "            if current_frame % FACE_EVENT_PERIOD == 0:\n",
    "                out.write(frame.astype('uint8'))\n",
    "            \n",
    "        elif detectMotion(comparison_frames[ref], gray, frame):\n",
    "            # Nonevent period just ended\n",
    "            if state == 1:\n",
    "                print(\"Face Detected, non-event period just ended!\")\n",
    "            state = 2\n",
    "            if current_frame % MOTION_EVENT_PERIOD == 0:\n",
    "                out.write(frame.astype('uint8'))\n",
    "            \n",
    "        else:\n",
    "            # If state is still 2 or 3, event just ended (reset vars)\n",
    "            if state > 1:\n",
    "                print(\"Motion just ended, non-event period starting now!\")\n",
    "                grab_period = MOTION_EVENT_PERIOD\n",
    "                elapsed_frames = 0\n",
    "                doubler = vs.get(cv2.CAP_PROP_FPS)\n",
    "            \n",
    "            elapsed_frames += 1\n",
    "            if elapsed_frames > doubler:\n",
    "                doubler *= 2\n",
    "                grab_period *= 2\n",
    "                print(f\"Current non-event playback speed: {grab_period}x\")\n",
    "            \n",
    "            if current_frame % grab_period == 0:\n",
    "                cv2.putText(frame, f\"{grab_period}x Speed\", (20,30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                out.write(frame.astype('uint8'))\n",
    "            state = 1            \n",
    "        \n",
    "        # Update reference frame and circular array\n",
    "        ref = (ref + 1) % FRAME_COMPARISON_DISTANCE\n",
    "        if ref == 0:\n",
    "            comparison_frames[-1] = gray\n",
    "        else:\n",
    "            comparison_frames[ref - 1] = gray\n",
    "\n",
    "        # Display image\n",
    "        if DISPLAY_IMAGE:\n",
    "            cv2.imshow(\"Frame\", frame)        \n",
    "        \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "vs.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
